{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cf1059",
   "metadata": {},
   "source": [
    "# EDA and Data Cleaning\n",
    "In this notebook I am going to further investigate the dataset and am going to clean it, if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f4ead",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Let's start with further exploring the dataset. As a first step, let's first create a pandas dataframe containing all image filenames and their class. This helps to easily plot the data distribution and to create different data splits and to maybe oversample the dataset in a later step (in case there is some imbalance present). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a78a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size_image(image_path):\n",
    "    image = plt.imread(image_path)\n",
    "    dimensions = image.shape\n",
    "    # check if last is missing -> image is grayscale -> add depth of 1\n",
    "    if len(dimensions) < 3:\n",
    "        return np.expand_dims(image, axis=-1).shape\n",
    "    else:\n",
    "        return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d868732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dataset_path):\n",
    "    # first step: get list of files\n",
    "    list_files = glob.glob(os.path.join(dataset_path, \"**\", \"*.jpg\"))\n",
    "    \n",
    "    # next step: get list of labels\n",
    "    list_labels = list(map(lambda x: x.split(os.path.sep)[1], list_files))\n",
    "    \n",
    "    # loop over classes and get all images per class\n",
    "    # first: let's create the empty dataframe\n",
    "    df = pd.DataFrame(columns=[\"filepath\", \"class_name\", \"image_height\", \"image_width\", \"image_depth\"])\n",
    "    df[\"image_height\"] = df[\"image_height\"].astype(int)\n",
    "    df[\"image_width\"] = df[\"image_width\"].astype(int)\n",
    "    df[\"image_depth\"] = df[\"image_depth\"].astype(int)\n",
    "    # loop over images to add each to the dataframe plus get dimensions of image\n",
    "    for image, label in zip(list_files, list_labels):\n",
    "        # remove dataset foldername from path\n",
    "        image_shorthened = os.path.sep.join(image.split(os.path.sep)[1:])\n",
    "        height, width, depth = get_size_image(image)\n",
    "        df = df.append({\"filepath\":image_shorthened, \n",
    "                        \"class_name\":label, \n",
    "                        \"image_height\": height, \n",
    "                        \"image_width\": width, \n",
    "                        \"image_depth\": depth }, ignore_index=True)\n",
    "    \n",
    "    return df, list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_names = create_dataframe(\"dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4396e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9609835",
   "metadata": {},
   "source": [
    "Okay perfect! In Kaggle its stated that there should be 6862 images in total, so we've read out all images. Now let's plot the data distribution to get a better understanding of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ba80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class_name\"].hist()\n",
    "plt.title(\"Dataset Distribution.\")\n",
    "plt.xlabel(\"Class Name\", labelpad=10)\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4e1be",
   "metadata": {},
   "source": [
    "Okay. The dataset is definetly imbalanced! Let's later apply some imbalance strategies to check if model performance can be improved to the model trained on the imbalanced dataset. <br> <br>\n",
    "<b> IMPORTANT: </b> Don't change the distribution on the validation set and the hold-out test set! They should reflect the real data distribution! Therefore, we can first split the data into the according sets and could then later apply some imbalance strategies only on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a873b1b1",
   "metadata": {},
   "source": [
    "## Image Sizes\n",
    "Let's now check the size of all images and if they are different frome each other. This is important, because the model needs to have images of fixed size as input. <br> <br>\n",
    "When looking at the first rows of the dataframe, it gets clear that the images have different shapes. Therefore, it is important to later choose one image size where all images should be resized to. The optimal image size can be searched by training models on the different image sizes and then comparing their performance. <br> <br>\n",
    "Let's now quickly check for the largest and the smallest image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5184f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Min height: {df[\"image_height\"].min()} | Max height: {df[\"image_height\"].max()}')\n",
    "print(f'Min width: {df[\"image_width\"].min()} | Max width: {df[\"image_width\"].max()}')\n",
    "print(f'Min depth: {df[\"image_depth\"].min()} | Max depth: {df[\"image_depth\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaef281",
   "metadata": {},
   "source": [
    "Okay so the ranges are quite large! There are also grayscale images, rgb images and even some images which also include a transparent layer (some transparent map above the image with certain alpha). I always tend to train my networks on grayscale images, because I often realized that having rgb images didn't boost the models performance. But let's first keep the images in their original format, except the images having depth of 4. They can be transformed to rgb by dropping the fourth depth dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad210603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_file(row):\n",
    "    dimension = row[-1]\n",
    "    if dimension == 4 and row[0]:\n",
    "        image = plt.imread(os.path.join(\"dataset\", row[0]))\n",
    "        plt.imsave(os.path.join(\"dataset\", row[0]), image[:, :, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92201a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(clean_file, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a832b589",
   "metadata": {},
   "source": [
    "Let's now reload the data and check if this problem is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_names = create_dataframe(\"dataset\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f86522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ba040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Min height: {df[\"image_height\"].min()} | Max height: {df[\"image_height\"].max()}')\n",
    "print(f'Min width: {df[\"image_width\"].min()} | Max width: {df[\"image_width\"].max()}')\n",
    "print(f'Min depth: {df[\"image_depth\"].min()} | Max depth: {df[\"image_depth\"].max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e8a18",
   "metadata": {},
   "source": [
    "Perfect! Let's now store the created dataframe as csv file such that it can be easily accessed later during the model training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv(r\"dataset\\data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42188f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
